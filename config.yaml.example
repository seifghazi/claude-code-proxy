# LLM Proxy Configuration Example
# This file demonstrates all available configuration options
# Copy this file to config.yaml and customize as needed

# Server configuration
server:
  # Port to listen on (default: 3001)
  port: 3001
  
  # Timeout configurations
  timeouts:
    # Maximum duration for reading the entire request, including the body
    read: 10m
    
    # Maximum duration before timing out writes of the response
    write: 10m
    
    # Maximum amount of time to wait for the next request when keep-alives are enabled
    idle: 10m

# Provider configurations
providers:
  # Anthropic Claude configuration
  anthropic:
    # Base URL for Anthropic API (can be changed for custom endpoints)
    base_url: "https://api.anthropic.com"
    
    # Maximum number of retries for failed requests
    max_retries: 3
  
  # OpenAI configuration
  openai:
    # API key for OpenAI
    # Can also be set via OPENAI_API_KEY environment variable
    # api_key: "sk-..."
    
    # Base URL for OpenAI API (can be changed for custom endpoints)
    # Can also be set via OPENAI_BASE_URL environment variable
    # base_url: "https://api.openai.com"
  
  # Google Gemini configuration
  gemini:
    # API key for Google Gemini
    # Can also be set via GEMINI_API_KEY environment variable
    # api_key: "AIza..."
    
    # Base URL for Gemini API
    # Can also be set via GEMINI_BASE_URL environment variable
    # base_url: "https://generativelanguage.googleapis.com"
  
  # OpenRouter configuration
  openrouter:
    # API key for OpenRouter
    # Can also be set via OPENROUTER_API_KEY environment variable
    # api_key: "sk-or-v1-..."
    
    # Base URL for OpenRouter API
    # Can also be set via OPENROUTER_BASE_URL environment variable
    # base_url: "https://openrouter.ai/api"

# Storage configuration
storage:
  # SQLite database path for storing request history
  db_path: "requests.db"
  
  # Directory for storing request files (if needed in future)
  # requests_dir: "./requests"

# Subagent Configuration (Optional)
# Enable this feature if you want to route specific Claude Code agents to different LLM providers
# For subagent setup instructions, see: https://docs.anthropic.com/en/docs/claude-code/sub-agents
subagents:
  # Enable subagent routing (default: false)
  enable: false
  
  # Maps subagent types to specific models
  # Only used when enable: true
  mappings:
    # Code review specialist - routes to OpenAI (example)
    # code-reviewer: "gpt-4o"
    
    # Data analysis expert - routes to Gemini (example)
    # data-analyst: "gemini-1.5-pro"
    
    # Documentation writer - routes to OpenRouter (example)
    # doc-writer: "openrouter/claude-3-haiku-20240307"
    
    # Deep reasoning specialist - routes to OpenRouter (example)
    # deep-reasoning: "openrouter/o3-mini"

# Environment variable overrides:
# The following environment variables will override the YAML configuration:
#
# Server:
#   PORT                      - Server port
#   READ_TIMEOUT             - Read timeout duration
#   WRITE_TIMEOUT            - Write timeout duration
#   IDLE_TIMEOUT             - Idle timeout duration
#
# Anthropic:
#   ANTHROPIC_FORWARD_URL    - Anthropic base URL
#   ANTHROPIC_VERSION        - Anthropic API version
#   ANTHROPIC_MAX_RETRIES    - Maximum retries for Anthropic requests
#
# OpenAI:
#   OPENAI_API_KEY           - OpenAI API key
#   OPENAI_BASE_URL          - OpenAI base URL
#
# Gemini:
#   GEMINI_API_KEY           - Google Gemini API key
#   GEMINI_BASE_URL          - Gemini base URL
#
# OpenRouter:
#   OPENROUTER_API_KEY       - OpenRouter API key
#   OPENROUTER_BASE_URL      - OpenRouter base URL
#
# Storage:
#   DB_PATH                  - Database file path
#
# Subagents:
#   SUBAGENT_MAPPINGS        - Comma-separated subagent:model pairs
#                              Example: "code-reviewer:claude-3-5-sonnet"